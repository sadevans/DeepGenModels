{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ad5485-242c-42cb-b607-5133708d2c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "# import torchvision\n",
    "import accelerate\n",
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "from IPython.display import display\n",
    "import os\n",
    "# import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff469bd-337d-476a-9407-3c860faeceea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch                    2.7.0\n",
      "torchaudio               2.7.0\n",
      "torchvision              0.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec69ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['INSTANCE_DIR'] = \"./data/instance_images\"\n",
    "os.environ['CLASS_DIR'] = \"./data/class_images\"\n",
    "\n",
    "os.environ['MODEL_NAME'] = \"./cache_dir/models/civitai_model\"\n",
    "os.environ['OUTPUT_DIR'] = \"./experiments/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5059709",
   "metadata": {},
   "source": [
    "## Define inference prompts and method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00f4a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(\n",
    "    pipe,\n",
    "    prompts_list,\n",
    "    negative_prompt,\n",
    "    save_dir=\"outputs\",\n",
    "    name_exp=\"experiment\",\n",
    "    num_samples=4,\n",
    "    guidance_scale=7.5,\n",
    "    num_inference_steps=35,\n",
    "    height=768,\n",
    "    width=1024,\n",
    "    generator=None\n",
    "):\n",
    "    exp_dir = os.path.join(save_dir, name_exp)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    for prompt_idx, prompt in enumerate(prompts_list):\n",
    "        print(f\"Generating images for prompt {prompt_idx + 1}/{len(prompts_list)}: {prompt}\")\n",
    "        \n",
    "        with autocast(device), torch.inference_mode():\n",
    "            images = pipe(\n",
    "                prompt,\n",
    "                height=height,\n",
    "                width=width,\n",
    "                negative_prompt=negative_prompt,\n",
    "                num_images_per_prompt=num_samples,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                guidance_scale=guidance_scale,\n",
    "                generator=generator\n",
    "            ).images\n",
    "        \n",
    "        for img_idx, img in enumerate(images):\n",
    "            filename = f\"prompt{prompt_idx+1}_img{img_idx+1}.png\"\n",
    "            save_path = os.path.join(exp_dir, filename)\n",
    "            img.save(save_path)\n",
    "            print(f\"Saved: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fafa72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompts = [\n",
    "    \"portrait of sks woman face, on the street, lights, midnight, NY, standing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\",\n",
    "    \"portrait of sks woman face, in the desert, wearing a dress, sun, pyramids, сamels, Egypt, standing, standing alone, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\",\n",
    "    \"portrait of sks woman face, in the game of thrones, wearing a dress, holding a knife, standing alone aside, dragons nearby, sad face, snowing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\",\n",
    "    \"portrait of sks woman face, cinderella, in the princess castle with rainbow, smiling, extremely happy, standing in the full height, cartoon, 4K, raw, hrd, hd, high quality, sharp focus\",\n",
    "    \"portrait of sks tall woman, astronaut, moon, space, standing in full height, 4K, raw, hrd, hd, high quality, sharp focus\",\n",
    "]\n",
    "negative_prompt = \"naked, nsfw, deformed, distorted, disfigured, poorly drawn, bad anatomy, extra limb, missing limb, floating limbs, mutated hands disconnected limbs, mutation, ugly, blurry, amputation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b8efe5-e0e1-4b11-84a1-519fc574ed4c",
   "metadata": {},
   "source": [
    "# Обучаем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6948a25-6a00-41b9-aece-72f60f06d4ed",
   "metadata": {},
   "source": [
    "## exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14d8b07a-1a2c-4612-94e2-41a0036caf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(os.environ['OUTPUT_DIR'], \"exp1_v1\")\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45f92068-9273-4177-9566-69f43af0358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --class_data_dir=$CLASS_DIR \\\n",
    "  --output_dir=$OUTPUT_DIR \\\n",
    "  --instance_prompt=\"a photo of sks woman face\" \\\n",
    "  --class_prompt=\"a photo of woman face \" \\\n",
    "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --learning_rate=2e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --num_class_images=500 \\\n",
    "  --max_train_steps=800 \\\n",
    "  --checkpointing_steps=800 \\\n",
    "  --use_8bit_adam \\\n",
    "  --mixed_precision=\"no\"\\\n",
    "  --train_text_encoder \\\n",
    "  --seed 31 > log 2> mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4c67b",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3425a424-5e02-4d78-94b2-08f3b1e13088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  4.05it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images for prompt 1/5: portrait of sks woman face, on the street, lights, midnight, NY, standing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp1/prompt1_img1.png\n",
      "Generating images for prompt 2/5: portrait of sks woman face, in the desert, wearing a dress, sun, pyramids, сamels, Egypt, standing, standing alone, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp1/prompt2_img1.png\n",
      "Generating images for prompt 3/5: portrait of sks woman face, in the game of thrones, wearing a dress, holding a knife, standing alone aside, dragons nearby, sad face, snowing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp1/prompt3_img1.png\n",
      "Generating images for prompt 4/5: portrait of sks woman face, cinderella, in the princess castle with rainbow, smiling, extremely happy, standing in the full height, cartoon, 4K, raw, hrd, hd, high quality, sharp focus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp1/prompt4_img1.png\n",
      "Generating images for prompt 5/5: portrait of sks tall woman, astronaut, moon, space, standing in full height, 4K, raw, hrd, hd, high quality, sharp focus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp1/prompt5_img1.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "model_path = output_path\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "g_cuda = torch.Generator(device='cuda')\n",
    "seed = 31\n",
    "g_cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "generate_images(\n",
    "    pipe=pipe,\n",
    "    prompts_list=prompts,\n",
    "    negative_prompt=negative_prompt,\n",
    "    save_dir=\"./results/\",\n",
    "    name_exp=\"exp1\",\n",
    "    num_samples=1,\n",
    "    generator=g_cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a25a7c",
   "metadata": {},
   "source": [
    "## exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c827c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(os.environ['OUTPUT_DIR'], \"exp2\")\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cfedb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./experiments/exp2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f9902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export CUDA_VISIBLE_DEVICES=0\n",
    "!python ./diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --class_data_dir=$CLASS_DIR \\\n",
    "  --output_dir=output_path \\\n",
    "  --instance_prompt=\"a photo of sks woman face\" \\\n",
    "  --class_prompt=\"a photo of woman face \" \\\n",
    "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --learning_rate=1e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --num_class_images=500 \\\n",
    "  --max_train_steps=800 \\\n",
    "  --checkpointing_steps=800 \\\n",
    "  --use_8bit_adam \\\n",
    "  --mixed_precision=\"no\"\\\n",
    "  --train_text_encoder \\\n",
    "  --seed 31 > ./dumps/log2 2> ./dumps/mistakes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b806f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a653753a",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12768f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./experiments/exp2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = output_path\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a64936f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:  17%|█▋        | 1/6 [00:00<00:01,  4.80it/s]/ssd/a.gorokhova/usr/anaconda3/envs/genmodels/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  4.27it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images for prompt 1/5: portrait of sks woman face, on the street, lights, midnight, NY, standing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35 [00:00<?, ?it/s]/ssd/a.gorokhova/usr/anaconda3/envs/genmodels/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "100%|██████████| 35/35 [00:04<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp2/prompt1_img1.png\n",
      "Generating images for prompt 2/5: portrait of sks woman face, in the desert, wearing a dress, sun, pyramids, сamels, Egypt, standing, standing alone, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp2/prompt2_img1.png\n",
      "Generating images for prompt 3/5: portrait of sks woman face, in the game of thrones, wearing a dress, holding a knife, standing alone aside, dragons nearby, sad face, snowing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp2/prompt3_img1.png\n",
      "Generating images for prompt 4/5: portrait of sks woman face, cinderella, in the princess castle with rainbow, smiling, extremely happy, standing in the full height, cartoon, 4K, raw, hrd, hd, high quality, sharp focus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp2/prompt4_img1.png\n",
      "Generating images for prompt 5/5: portrait of sks tall woman, astronaut, moon, space, standing in full height, 4K, raw, hrd, hd, high quality, sharp focus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp2/prompt5_img1.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained('./experiments/', safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "g_cuda = torch.Generator(device='cuda')\n",
    "seed = 31\n",
    "g_cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "generate_images(\n",
    "    pipe=pipe,\n",
    "    prompts_list=prompts,\n",
    "    negative_prompt=negative_prompt,\n",
    "    save_dir=\"./results/\",\n",
    "    name_exp=\"exp2\",\n",
    "    num_samples=1,\n",
    "    generator=g_cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f571465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44828e58",
   "metadata": {},
   "source": [
    "## exp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82330da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./experiments/exp3'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = os.path.join(os.environ['OUTPUT_DIR'], \"exp3\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9f810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export CUDA_VISIBLE_DEVICES=0\n",
    "!python ./diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --class_data_dir=$CLASS_DIR \\\n",
    "  --output_dir=$output_path \\\n",
    "  --instance_prompt=\"a photo of sks woman face\" \\\n",
    "  --class_prompt=\"a photo of woman face \" \\\n",
    "  --with_prior_preservation \\\n",
    "  --prior_loss_weight=1.2 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --learning_rate=2e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --num_class_images=500 \\\n",
    "  --max_train_steps=800 \\\n",
    "  --checkpointing_steps=800 \\\n",
    "  --use_8bit_adam \\\n",
    "  --mixed_precision=\"no\"\\\n",
    "  --train_text_encoder \\\n",
    "  --seed 31 > ./dumps/log3 2> ./dumps/mistakes3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a79154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c80d1ecb",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e8bf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./experiments/exp3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = output_path\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea941b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00,  6.37it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images for prompt 1/5: portrait of sks woman face, on the street, lights, midnight, NY, standing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp3/prompt1_img1.png\n",
      "Generating images for prompt 2/5: portrait of sks woman face, in the desert, wearing a dress, sun, pyramids, сamels, Egypt, standing, standing alone, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp3/prompt2_img1.png\n",
      "Generating images for prompt 3/5: portrait of sks woman face, in the game of thrones, wearing a dress, holding a knife, standing alone aside, dragons nearby, sad face, snowing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp3/prompt3_img1.png\n",
      "Generating images for prompt 4/5: portrait of sks woman face, cinderella, in the princess castle with rainbow, smiling, extremely happy, standing in the full height, cartoon, 4K, raw, hrd, hd, high quality, sharp focus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp3/prompt4_img1.png\n",
      "Generating images for prompt 5/5: portrait of sks tall woman, astronaut, moon, space, standing in full height, 4K, raw, hrd, hd, high quality, sharp focus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp3/prompt5_img1.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "g_cuda = torch.Generator(device='cuda')\n",
    "seed = 31\n",
    "g_cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "generate_images(\n",
    "    pipe=pipe,\n",
    "    prompts_list=prompts,\n",
    "    negative_prompt=negative_prompt,\n",
    "    save_dir=\"./results/\",\n",
    "    name_exp=\"exp3\",\n",
    "    num_samples=1,\n",
    "    generator=g_cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861cd98",
   "metadata": {},
   "source": [
    "# Lora training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8a5a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cff76230",
   "metadata": {},
   "source": [
    "## exp1_lora\n",
    "\n",
    "rank = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5ba8527",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python diffusers/examples/dreambooth/train_dreambooth_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"./experiments/exp1_v1\" \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --output_dir=\"./lora_outputs/exp1_v1/\" \\\n",
    "  --instance_prompt=\"a photo of sks woman face\" \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --learning_rate=1e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=200 \\\n",
    "  --checkpointing_steps=20 \\\n",
    "  --use_8bit_adam \\\n",
    "  --mixed_precision=\"no\"\\\n",
    "  --train_text_encoder \\\n",
    "  --validation_prompt=\"a photo of sks woman face in NYC, rain, dark, night, full moon, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\" \\\n",
    "  --validation_epochs=50 \\\n",
    "  --seed=31 \\\n",
    "  --rank=32 > ./dumps/log_lora1 2> ./dumps/mistakes_lora1\n",
    "  # --report_to=\"clearml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6357a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09c0057f",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1394381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lora_pipeline(model_path, lora_path):\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        model_path, \n",
    "        safety_checker=None, \n",
    "        torch_dtype=torch.float16\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    pipe.unet.load_attn_procs(lora_path)\n",
    "    \n",
    "    pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26f3037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images for prompt 1/5: portrait of sks woman face, on the street, lights, midnight, NY, standing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp1_lora/prompt1_img1.png\n",
      "Generating images for prompt 2/5: portrait of sks woman face, in the desert, wearing a dress, sun, pyramids, сamels, Egypt, standing, standing alone, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp1_lora/prompt2_img1.png\n",
      "Generating images for prompt 3/5: portrait of sks woman face, in the game of thrones, wearing a dress, holding a knife, standing alone aside, dragons nearby, sad face, snowing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp1_lora/prompt3_img1.png\n",
      "Generating images for prompt 4/5: portrait of sks woman face, cinderella, in the princess castle with rainbow, smiling, extremely happy, standing in the full height, cartoon, 4K, raw, hrd, hd, high quality, sharp focus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp1_lora/prompt4_img1.png\n",
      "Generating images for prompt 5/5: portrait of sks tall woman, astronaut, moon, space, standing in full height, 4K, raw, hrd, hd, high quality, sharp focus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp1_lora/prompt5_img1.png\n"
     ]
    }
   ],
   "source": [
    "lora_path = \"./lora_outputs/exp1_v1/\"  # Путь к обученной LoRA\n",
    "\n",
    "g_cuda = torch.Generator(device='cuda')\n",
    "seed = 31\n",
    "g_cuda.manual_seed(seed)\n",
    "\n",
    "pipe = load_lora_pipeline(\"./experiments/exp1_v1\", lora_path)\n",
    "generate_images(\n",
    "    pipe=pipe,\n",
    "    prompts_list=prompts,\n",
    "    negative_prompt=negative_prompt,\n",
    "    save_dir=\"./results/\",\n",
    "    name_exp=\"exp1_lora\",\n",
    "    num_samples=1,\n",
    "    generator=g_cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b62f2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27f7e059",
   "metadata": {},
   "source": [
    "## exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e58ce27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python diffusers/examples/dreambooth/train_dreambooth_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"./experiments/exp1_v1\" \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --output_dir=\"./lora_outputs/exp2/\" \\\n",
    "  --instance_prompt=\"a photo of sks woman face\" \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --learning_rate=1e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=200 \\\n",
    "  --checkpointing_steps=20 \\\n",
    "  --use_8bit_adam \\\n",
    "  --mixed_precision=\"no\"\\\n",
    "  --train_text_encoder \\\n",
    "  --validation_prompt=\"a photo of sks woman face in NYC, rain, dark, night, full moon, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\" \\\n",
    "  --validation_epochs=50 \\\n",
    "  --seed=31 \\\n",
    "  --rank=64 > ./dumps/log_lora1 2> ./dumps/mistakes_lora1\n",
    "  # --report_to=\"clearml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae3a48",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5688f8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:  50%|█████     | 3/6 [00:06<00:06,  2.22s/it]/ssd/a.gorokhova/usr/anaconda3/envs/genmodels/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "/ssd/a.gorokhova/usr/anaconda3/envs/genmodels/lib/python3.10/site-packages/diffusers/loaders/unet.py:212: FutureWarning: `load_attn_procs` is deprecated and will be removed in version 0.40.0. Using the `load_attn_procs()` method has been deprecated and will be removed in a future version. Please use `load_lora_adapter()`.\n",
      "  deprecate(\"load_attn_procs\", \"0.40.0\", deprecation_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images for prompt 1/5: portrait of sks woman face, on the street, lights, midnight, NY, standing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35 [00:00<?, ?it/s]/ssd/a.gorokhova/usr/anaconda3/envs/genmodels/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "100%|██████████| 35/35 [00:05<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp2_lora/prompt1_img1.png\n",
      "Generating images for prompt 2/5: portrait of sks woman face, in the desert, wearing a dress, sun, pyramids, сamels, Egypt, standing, standing alone, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp2_lora/prompt2_img1.png\n",
      "Generating images for prompt 3/5: portrait of sks woman face, in the game of thrones, wearing a dress, holding a knife, standing alone aside, dragons nearby, sad face, snowing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp2_lora/prompt3_img1.png\n",
      "Generating images for prompt 4/5: portrait of sks woman face, cinderella, in the princess castle with rainbow, smiling, extremely happy, standing in the full height, cartoon, 4K, raw, hrd, hd, high quality, sharp focus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp2_lora/prompt4_img1.png\n",
      "Generating images for prompt 5/5: portrait of sks tall woman, astronaut, moon, space, standing in full height, 4K, raw, hrd, hd, high quality, sharp focus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp2_lora/prompt5_img1.png\n"
     ]
    }
   ],
   "source": [
    "lora_path = \"./lora_outputs/exp2/\"  # Путь к обученной LoRA\n",
    "\n",
    "g_cuda = torch.Generator(device='cuda')\n",
    "seed = 31\n",
    "g_cuda.manual_seed(seed)\n",
    "\n",
    "pipe = load_lora_pipeline(\"./experiments/exp1_v1\", lora_path)\n",
    "generate_images(\n",
    "    pipe=pipe,\n",
    "    prompts_list=prompts,\n",
    "    negative_prompt=negative_prompt,\n",
    "    save_dir=\"./results/\",\n",
    "    name_exp=\"exp2_lora\",\n",
    "    num_samples=1,\n",
    "    generator=g_cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0df9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb87fd65",
   "metadata": {},
   "source": [
    "## exp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8046b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python diffusers/examples/dreambooth/train_dreambooth_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"./experiments/exp1_v1\" \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --output_dir=\"./lora_outputs/exp3/\" \\\n",
    "   --instance_prompt=\"a photo of sks woman face\" \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --learning_rate=1e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=200 \\\n",
    "  --checkpointing_steps=20 \\\n",
    "  --use_8bit_adam \\\n",
    "  --mixed_precision=\"no\"\\\n",
    "  --train_text_encoder \\\n",
    "  --validation_prompt=\"a photo of sks woman face in NYC, rain, dark, night, full moon, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\" \\\n",
    "  --validation_epochs=50 \\\n",
    "  --seed=31 \\\n",
    "  --rank=16 > ./dumps/log_lora1 2> ./dumps/mistakes_lora1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dac8c79",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "601870e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images for prompt 1/5: portrait of sks woman face, on the street, lights, midnight, NY, standing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp3_lora/prompt1_img1.png\n",
      "Generating images for prompt 2/5: portrait of sks woman face, in the desert, wearing a dress, sun, pyramids, сamels, Egypt, standing, standing alone, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp3_lora/prompt2_img1.png\n",
      "Generating images for prompt 3/5: portrait of sks woman face, in the game of thrones, wearing a dress, holding a knife, standing alone aside, dragons nearby, sad face, snowing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp3_lora/prompt3_img1.png\n",
      "Generating images for prompt 4/5: portrait of sks woman face, cinderella, in the princess castle with rainbow, smiling, extremely happy, standing in the full height, cartoon, 4K, raw, hrd, hd, high quality, sharp focus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp3_lora/prompt4_img1.png\n",
      "Generating images for prompt 5/5: portrait of sks tall woman, astronaut, moon, space, standing in full height, 4K, raw, hrd, hd, high quality, sharp focus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp3_lora/prompt5_img1.png\n"
     ]
    }
   ],
   "source": [
    "lora_path = \"./lora_outputs/exp3/\"  # Путь к обученной LoRA\n",
    "\n",
    "g_cuda = torch.Generator(device='cuda')\n",
    "seed = 31\n",
    "g_cuda.manual_seed(seed)\n",
    "\n",
    "pipe = load_lora_pipeline(\"./experiments/exp1_v1\", lora_path)\n",
    "generate_images(\n",
    "    pipe=pipe,\n",
    "    prompts_list=prompts,\n",
    "    negative_prompt=negative_prompt,\n",
    "    save_dir=\"./results/\",\n",
    "    name_exp=\"exp3_lora\",\n",
    "    num_samples=1,\n",
    "    generator=g_cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad81f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce88e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python diffusers/examples/dreambooth/train_dreambooth_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"./experiments/exp1_v1\" \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --output_dir=\"./lora_outputs/exp4/\" \\\n",
    "  --instance_prompt=\"a photo of sks woman face\" \\\n",
    "  --resolution=520 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --learning_rate=2e-5 \\\n",
    "  --lr_scheduler=\"cosine_with_restarts\" \\\n",
    "  --lr_warmup_steps=20 \\\n",
    "  --max_train_steps=300 \\\n",
    "  --checkpointing_steps=50 \\\n",
    "  --use_8bit_adam \\\n",
    "  --mixed_precision=\"no\" \\\n",
    "  --train_text_encoder \\\n",
    "  --validation_prompt=\"a photo of sks woman face in NYC, rain, dark, night, full moon\" \\\n",
    "  --validation_epochs=25 \\\n",
    "  --seed=31 \\\n",
    "  --rank=96 > ./dumps/log_lora1 2> ./dumps/mistakes_lora1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5ec827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:  50%|█████     | 3/6 [00:07<00:07,  2.55s/it]/ssd/a.gorokhova/usr/anaconda3/envs/genmodels/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:08<00:00,  1.48s/it]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "/ssd/a.gorokhova/usr/anaconda3/envs/genmodels/lib/python3.10/site-packages/diffusers/loaders/unet.py:212: FutureWarning: `load_attn_procs` is deprecated and will be removed in version 0.40.0. Using the `load_attn_procs()` method has been deprecated and will be removed in a future version. Please use `load_lora_adapter()`.\n",
      "  deprecate(\"load_attn_procs\", \"0.40.0\", deprecation_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images for prompt 1/5: portrait of sks woman face, on the street, lights, midnight, NY, standing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp4_lora/prompt1_img1.png\n",
      "Generating images for prompt 2/5: portrait of sks woman face, in the desert, wearing a dress, sun, pyramids, сamels, Egypt, standing, standing alone, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp4_lora/prompt2_img1.png\n",
      "Generating images for prompt 3/5: portrait of sks woman face, in the game of thrones, wearing a dress, holding a knife, standing alone aside, dragons nearby, sad face, snowing, 4K, raw, hrd, hd, high quality, realism, sharp focus, beautiful eyes, detailed eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp4_lora/prompt3_img1.png\n",
      "Generating images for prompt 4/5: portrait of sks woman face, cinderella, in the princess castle with rainbow, smiling, extremely happy, standing in the full height, cartoon, 4K, raw, hrd, hd, high quality, sharp focus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp4_lora/prompt4_img1.png\n",
      "Generating images for prompt 5/5: portrait of sks tall woman, astronaut, moon, space, standing in full height, 4K, raw, hrd, hd, high quality, sharp focus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/exp4_lora/prompt5_img1.png\n"
     ]
    }
   ],
   "source": [
    "lora_path = \"./lora_outputs/exp4/\"  # Путь к обученной LoRA\n",
    "\n",
    "g_cuda = torch.Generator(device='cuda')\n",
    "seed = 31\n",
    "g_cuda.manual_seed(seed)\n",
    "\n",
    "pipe = load_lora_pipeline(\"./experiments/exp1_v1\", lora_path)\n",
    "generate_images(\n",
    "    pipe=pipe,\n",
    "    prompts_list=prompts,\n",
    "    negative_prompt=negative_prompt,\n",
    "    save_dir=\"./results/\",\n",
    "    name_exp=\"exp4_lora\",\n",
    "    num_samples=1,\n",
    "    generator=g_cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d471b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "210c29e7",
   "metadata": {},
   "source": [
    "# ControlNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf310d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from diffusers import UNet2DConditionModel\n",
    "from diffusers.utils import load_image\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89bbbff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_control_image(image_path, control_type=\"canny\"):\n",
    "    \"\"\"\n",
    "    Подготовка контрольного изображения для ControlNet\n",
    "    Args:\n",
    "        image_path (str): путь к исходному изображению\n",
    "        control_type (str): тип ControlNet\n",
    "    Returns:\n",
    "        control_image: обработанное изображение\n",
    "    \"\"\"\n",
    "    image = load_image(image_path)\n",
    "    image = np.array(image)\n",
    "    \n",
    "    if control_type == \"canny\":\n",
    "        import cv2\n",
    "        image = cv2.Canny(image, 100, 200)\n",
    "        image = image[:, :, None]\n",
    "        image = np.concatenate([image, image, image], axis=2)\n",
    "        control_image = Image.fromarray(image)\n",
    "    elif control_type == \"depth\":\n",
    "        from transformers import pipeline\n",
    "        depth_estimator = pipeline(\"depth-estimation\")\n",
    "        control_image = depth_estimator(Image.fromarray(image))[\"depth\"]\n",
    "    elif control_type == \"pose\":\n",
    "        from controlnet_aux import OpenposeDetector\n",
    "        processor = OpenposeDetector.from_pretrained(\"lllyasviel/ControlNet\")\n",
    "        control_image = processor(Image.fromarray(image))\n",
    "    else:\n",
    "        control_image = image\n",
    "    \n",
    "    return control_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41667968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_controlnet_pipeline(unet_path=None, lora_path=None, controlnet_type=\"canny\"):\n",
    "    # Load base ControlNet model\n",
    "    controlnet = ControlNetModel.from_pretrained(\n",
    "        f\"lllyasviel/sd-controlnet-{controlnet_type}\",\n",
    "        torch_dtype=torch.float16\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    # Initialize pipeline\n",
    "    pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "        unet_path,\n",
    "        controlnet=controlnet,\n",
    "        torch_dtype=torch.float16,\n",
    "        safety_checker=None\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    # Load LoRA weights if provided\n",
    "    if lora_path is not None:\n",
    "        pipe.load_lora_weights(lora_path)\n",
    "    \n",
    "    # Optimizations\n",
    "    pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "    pipe.enable_model_cpu_offload()\n",
    "    pipe.enable_xformers_memory_efficient_attention()\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "\n",
    "def generate_images(\n",
    "    pipe,\n",
    "    base_prompts,\n",
    "    control_image,\n",
    "    negative_prompt=None,\n",
    "    output_dir=\"controlnet_outputs\",\n",
    "    exp_name='experiment',\n",
    "    seed=42,\n",
    "    num_samples=4,\n",
    "    num_inference_steps=20,\n",
    "    guidance_scale=7.5,\n",
    "    controlnet_conditioning_scale=0.8\n",
    "):\n",
    "    output_path = os.path.join(output_dir, exp_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Prepare prompts\n",
    "    prompt_suffix = \", best quality, extremely detailed, 4k, hdr, super resolution\"\n",
    "    prompts = [t + prompt_suffix for t in base_prompts]\n",
    "    \n",
    "    # Prepare negative prompt\n",
    "    if negative_prompt is None:\n",
    "        negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n",
    "    negative_prompts = [negative_prompt] * len(prompts)\n",
    "    \n",
    "    # Prepare generators\n",
    "    generators = [torch.Generator(device=\"cuda\").manual_seed(seed + i) for i in range(len(prompts))]\n",
    "    \n",
    "    # Generate images\n",
    "    results = pipe(\n",
    "        prompt=prompts,\n",
    "        image=control_image,\n",
    "        negative_prompt=negative_prompts,\n",
    "        generator=generators,\n",
    "        num_images_per_prompt=num_samples,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        controlnet_conditioning_scale=controlnet_conditioning_scale\n",
    "    )\n",
    "    \n",
    "    # Save images\n",
    "    for i, image in enumerate(results.images):\n",
    "        image.save(os.path.join(output_path, f\"prompt{i+1}_image{i+1}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea9ba9",
   "metadata": {},
   "source": [
    "### exp1 - canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3304147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00,  8.21it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "pipe1 = load_controlnet_pipeline(\n",
    "        unet_path=\"/netapp/a.gorokhova/itmo/DeepGenModels/hw4/experiments/exp1_v1\",\n",
    "        lora_path=\"/netapp/a.gorokhova/itmo/DeepGenModels/hw4/lora_outputs/exp4/\",\n",
    "        controlnet_type=\"canny\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1609d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to Intel/dpt-large and revision bc15f29 (https://huggingface.co/Intel/dpt-large).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DPTForDepthEstimation were not initialized from the model checkpoint at Intel/dpt-large and are newly initialized: ['neck.fusion_stage.layers.0.residual_layer1.convolution1.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution1.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "input_image_path = \"./control_images/style_arcane.jpg\"  # Replace with your image path\n",
    "canny_image = prepare_control_image(input_image_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83d27224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  5.99it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_images(\n",
    "        pipe=pipe1,\n",
    "        base_prompts=prompts,\n",
    "        negative_prompt=negative_prompt,\n",
    "        control_image=canny_image,\n",
    "        num_samples=1,\n",
    "        output_dir=\"./results/\",\n",
    "        exp_name='exp1_controlnet',\n",
    "        seed=31,\n",
    "        num_inference_steps=35,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed6c6f1",
   "metadata": {},
   "source": [
    "### exp2 - depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c154e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00,  7.63it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 35/35 [00:05<00:00,  5.86it/s]\n"
     ]
    }
   ],
   "source": [
    "depth_image = prepare_control_image(input_image_path, control_type=\"depth\")\n",
    "pipe2 = load_controlnet_pipeline(\n",
    "        unet_path=\"/netapp/a.gorokhova/itmo/DeepGenModels/hw4/experiments/exp1_v1\",\n",
    "        lora_path=\"/netapp/a.gorokhova/itmo/DeepGenModels/hw4/lora_outputs/exp4/\",\n",
    "        controlnet_type=\"depth\"\n",
    "    )\n",
    "\n",
    "\n",
    "generate_images(\n",
    "        pipe=pipe2,\n",
    "        base_prompts=prompts,\n",
    "        negative_prompt=negative_prompt,\n",
    "        control_image=depth_image,\n",
    "        num_samples=1,\n",
    "        output_dir=\"./results/\",\n",
    "        exp_name='exp2_controlnet',\n",
    "        seed=31,\n",
    "        num_inference_steps=35,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c3f997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1163245",
   "metadata": {},
   "source": [
    "### exp3 - pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2cd7331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00,  7.57it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 35/35 [00:19<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "pose_image = prepare_control_image(input_image_path, control_type=\"pose\")\n",
    "\n",
    "pipe3 = load_controlnet_pipeline(\n",
    "        unet_path=\"/netapp/a.gorokhova/itmo/DeepGenModels/hw4/experiments/exp1_v1\",\n",
    "        lora_path=\"/netapp/a.gorokhova/itmo/DeepGenModels/hw4/lora_outputs/exp4/\",\n",
    "        controlnet_type=\"openpose\"\n",
    "    )\n",
    "\n",
    "generate_images(\n",
    "        pipe=pipe3,\n",
    "        base_prompts=prompts,\n",
    "        negative_prompt=negative_prompt,\n",
    "        control_image=pose_image,\n",
    "        num_samples=1,\n",
    "        output_dir=\"./results/\",\n",
    "        exp_name='exp3_controlnet',\n",
    "        seed=31,\n",
    "        num_inference_steps=35,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genmodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
